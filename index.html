<!DOCTYPE html>
<html>
    <head>
        <link href="//maxcdn.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" rel="stylesheet" id="bootstrap-css">
        <!-- <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"> -->
        <script src="https://code.jquery.com/jquery-3.3.1.js"></script>
        <script src="//maxcdn.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/responsive-tabs@1.6.3/js/jquery.responsiveTabs.min.js"></script>
        <!-- <script src='https://kit.fontawesome.com/a076d05399.js'></script> -->

        <title>NYU-Indoor-VPR Dataset</title>
        <link href="style.css" rel='stylesheet' type='text/css'>
        <script src="scripts.js"></script>
    </head>

    <body>
        <nav>
            <a class="logo" href="https://ai4ce.github.io">
                <img src="imgs/ai4ce_linear.png">
                <!-- <img src="imgs/ai4ce.png"> -->
            </a>
            <div class="menu">
                <ul>
                    <li><a href="#">Home</a></li>
                    <li><a href="#intro">Introduction</a></li>
                    <li><a href="#desp">Description</a></li>
                    <li><a href="#download">Download</a></li>
                    <!-- <li><a href="#exp">Experiences</a></li> -->
                    <li><a href="#contact">Contact</a></li>
                    <li><a href="#acknowledge">Acknowledgment</a></li>
                </ul>
            </div>
        </nav>
        <div class="head_container">
            <header class="main_header">
                <div class="box">
                    <div class="title">NYU-Indoor-VPR Dataset Website</div>
                    <hr class="line">
                    <div class="description">This is the official website for paper NYU-Indoor-VPR</a></div>
                </div>
            </header>
        </div>
        
        <section class="main_section" id="intro">
            <div class="content">
                <h1>Introduction</h1>
                <hr class="horizontalLine">
                <p>Our dataset is named NYU-Indoor-VPR. It is composed of images recorded in New York City from April 2022 to April 2023. Footage was captured using hand-held Insta360 one x2 spherical cameras,  generating videos with a resolution of 1920x960. On the basis of raw images, we use <a href="https://github.com/mseg-dataset/mseg-api" target="_blank" style="text-decoration: none; color: rgb(190, 80, 190);">MSeg</a>, a semantic segmentation method, to replace moving objects such as people and cars with white pixels. Fig. 1 compares anonymized and raw images.</p>

                <div>
                    <img class="imgs" src="imgs/non_anony.jpg" alt="non_anony">
                    <figcaption>Fig. 1 - Illustration of raw images and anonymized images</figcaption>
                </div>

                <p> We recorded images of 13 different floors/scenes within the six buildings. We chose buildings with varied utilities and appearances: the Oculus, New York University Silver Center for Arts and Science, Elmer Holmes Bobst Library, Morton Williams Supermarket, and Metropolitan Museum of Art. These settings represent a broad range of indoor spaces, including shopping malls, teaching buildings, libraries, supermarkets, and museums. Fig. 2 shows the trajectories and example images of certain scenes.</p>

                <div>
                    <img class="imgs" src="imgs/data_vis.jpg" alt="data_vis">
                    <figcaption>Fig. 2 - Trajectories annotated by our semi-automatic method and example images of 12 scenes in NYC-Indoor-VPR.</figcaption>
                </div>

                <p>For each building, we selected one or multiple floors as scenes. For each scene, we fixed the trajectory and captured videos along the same route at different times throughout the year. Fig. 3 shows the time distribution of visits. The videos were recorded from April to July 2022 and from March to April 2023. Therefore, it contains various changes in illumination and appearance. As shown in Fig. 4, we can see image changes at the same location over a year.</p>

                <div class="imgs">
                    <div class="half">
                        <img src="imgs/challenge_case.png" alt="challenge_case">
                        <figcaption>Fig. 3</figcaption>
                    </div>
                    <div class="half">
                        <img src="imgs/time_freq.png" alt="time_freq">
                        <figcaption>Fig. 4</figcaption>
                    </div>
                </div>

            </div>
        </section>

        <section class="main_section even_section" id="desp">
            <div class="content">
                <h1>Detail Description</h1>
                <hr class="horizontalLine">
                
                <div class="services-tabs">
                    <ul>
                        <li><a href="#desp1">Difficulty Level</a></li>
                        <li><a href="#desp2">Uniqueness</a></li>
                        <!-- <li><a href="#desp3">Front-View VS Side-View</a></li>
                        <li><a href="#desp4">Other Challenges</a></li> -->
                    </ul>
                    <br>

                    <div id="desp1" class="despTab">
                        <div class="despContainer">
                            <div>
                                <div class="tabBg">
                                    <h2>01</h2>
                                    <h3>Dataset Detail</h3>
                                    <img src="imgs/dataset_detail.jpg" alt="dataset_detail">
                                </div>
                            </div>
                        </div>
                    </div>

                    <div id="desp2" class="despTab">
                        <div class="despContainer">
                            <div>
                                <div class="tabBg">
                                    <h2>02</h2>
                                    <h3>Uniqueness</h3>
                                    <p>
                                        Our dataset stands out in two ways. First, NYC-Indoor-VPR images were captured in buildings such as The Oculus and the Bobst Library, which typically have a large flow of pedestrians. We anonymized these pedestrians in the images to reduce their exposure to personally identifiable information. These anonymized images not only enhance data privacy but also allow VPR algorithms to focus more on invariant or environmental features rather than transient features, such as moving people. Second, NYC-Indoor-VPR spans a year and includes images captured in buildings that undergo significant visual changes over time. For instance, goods in the supermarket vary and storefronts in the shopping mall are subject to change. This variability in the dataset allows us to test the performance of the VPR algorithms with fewer invariant features in the images.
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- <div id="desp3" class="despTab">
                        <div class="despContainer">
                            <div>
                                <div class="tabBg">
                                    <h2>03</h2>
                                    <h3>Front-View VS Side-View</h3>
                                    <p>
                                        Our dataset includes images in two view directions: front-view and side-view. Front-view images has a view direction that is parallel to the driving/street direction. Front-view images usually have features of roads, shapes of skylines, and textures of the roadside buildings. Contrarily, side-view images has a view direction facing buildings along street. Side view direction is perpendicular to front view direction.
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div id="desp4" class="despTab">
                        <div class="despContainer">
                            <div>
                                <div class="tabBg">
                                    <h2>04</h2>
                                    <h3>Other Challenges</h3>
                                    <p>
                                        Because our dataset is one-year long, the images taken at the same location have artificial or natural differences. First, Fig. 7 left was taken in October 2016 with sideway constructions and the right was taken in December 2016 after the construction. At some locations, the construction may cover the whole image. Second, different seasons cause different appearances at the same location. Fig. 8 left was taken in summer, July 2016, and the right was taken in winter, January 2017. In this case, the vegetation in Washington Square Park had changed a lot and snow was covering the ground in winter. Furthermore, if the vehicle was moving fast, the images taken by the vehicle will be blurry (Fig. 9). Although two images were taken at the same location, the blurry one will cause more difficulty during VPR.
                                    </p>
                                    <div class="imgContainer">
                                        <img src="imgs/construction.jpg" alt="construction">
                                        <figcaption>Fig. 7 During and After Construction</figcaption>
    
                                        <img src="imgs/park.jpg" alt="season">
                                        <figcaption>Fig. 8 Summer and Winter</figcaption>
    
                                        <img src="imgs/blur.jpg" alt="blur">
                                        <figcaption>Fig. 9 Without and With Motion Blur</figcaption>
                                    </div>
                                    
                                </div>
                            </div>
                        </div>
                    </div> -->

                </div>
            </div>
        </section>

        <section class="main_section" id="download">
            <div class="content">
                <h1>Download</h1>
                <hr class="horizontalLine">
                <p>Files are organized as a zip file contains images. The image name includes annotated topometric location and its index. Please fill a Google form through the following link to request dataset access.</p>
                <h3>Google Form Link: <a href="https://docs.google.com/forms/d/e/1FAIpQLScCHtnsHTcq5GfqpTPlLdJMAHXIv3SP83rkTk5IdHGKzqE6mQ/viewform?usp=pp_url" target="_blank">Please Click Here</a></h3>
                <p>Below is the Github repo of code used to perform experiments described in the paper.</p>
                <h3>Code Link: <a href="https://github.com/ai4ce/NYC-Indoor-VPR" target="_blank">Please Click Here</a></h3>
            </div>
        </section>

        <section class="main_section" id="contact">
            <div class="content">
                <h1>Contact Us</h1>
                <hr class="horizontalLine">
                <h3>Chen Feng - <a class="mail" href="mailto:cfeng@nyu.edu">cfeng@nyu.edu</a></h3>
                <h3>Diwei Sheng - <a class="mail" href="mailto:ds5725@nyu.edu">ds5725@nyu.edu</a></h3>
            </div>
        </section>
        
        <!-- <section class="main_section" id="acknowledge"> 
            <div class="content">
                <h1>Acknowledgment</h1>
                <hr class="horizontalLine">
                <p>The raw data from Carmera was obtained from <a href="https://vida.engineering.nyu.edu/" target="_blank">NYU VIDA lab</a> led by Professor Claudio Silva. The project was funded by <a href="https://c2smart.engineering.nyu.edu/" target="_blank">C2SMART</a>.</p>
                <div class="imgs">
                    <div class="half">
                        <img src="imgs/vida_logo.png" alt="vida_logo">
                    </div> 
                    <div class="half">
                        <img src="imgs/c2smart_logo.PNG" alt="c2smart_logo">
                    </div>
                </div>
            </div>
        </section> -->
    </body>
</html>
